---
title: 深度学习
category: Deep Learning
tags:
  - Algorithm
---

$$
\begin{align*}
\newcommand{\Hilbert}[1]{\mathscr{#1}}
\newcommand{\dd}{\operatorname{d}}
\newcommand{\op}{\hat}
\newcommand{\id}{\mathbf{I}}
\newcommand{\Tr}[1]{\operatorname{Tr}\left\lbrace#1\right\rbrace}
\newcommand{\realset}{\mathbb{R}}
\newcommand{\intset}{\mathbb Z }
\newcommand{\comset }{\mathbb C }
\newcommand{\innerproduct}[1]{\left\langle #1 \right\rangle}
\renewcommand{\vec}{\mathbf}
\newcommand{\spl}[1]{\langle{#1}\rangle}
\newcommand{\inner}[2]{\left\langle{#1,#2}\right\rangle}
\newcommand{\form}{\tilde}
\newcommand{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand{\bra}[1]{\left\langle{#1}\right\vert }
\newcommand{\ket}[1]{\left| {#1}\right\rangle}
\newcommand{\braket}[2]{\left\langle {#1} \; \middle|\;{#2} \right\rangle }
\newcommand{\mani}{\mathcal}
\newcommand{\field}{\mathscr}
\newcommand{\Tspace}[1]{T\! {#1}}
\newcommand{\D}[2]{\frac{\d {#1}}{\d {#2} }}
\newcommand{\Partial}[2]{\frac{\partial {#1} }{\partial {#2} }}
\newcommand{\op}{\hat}
\newcommand{\uvec}{\hat}
\newcommand{\defas}{: =}
\newcommand{\isdefas}{= :}
\newcommand{\Eqn}[1]{\text{(Eqn. }\ref{#1}\text{)}}
\newcommand{\dual}{\tilde}
\newcommand{\vard}{\mathfrak{d}}
\newcommand{\vare}{\mathfrak{e}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\ii}{\mathrm{i}}
\newcommand{\blue}{\color{blue}}
\newcommand{\red}{\color{red}}
\newcommand{\norm}[1]{\left\|{#1}\right\|}
\newcommand{\set}[1]{\left\lbrace{#1}\right\rbrace}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand\myeq{\stackrel{\mbox{adiabatic}}{=}}
\newcommand{\avg}[1]{\left\langle {#1} \right\rangle}
\end{align*}
$$

I just want to check is LaTex can work here $x^2$

#### 随机梯度下降

初始参数$\theta$，学习率$\epsilon$

> 从训练集总采包含m个样本的小批量$\{x^{(1)},\cdots,x^{(m)}\}$        
> 以小批量上的梯度均值作为(无偏)梯度估计：$\boldsymbol{g} \leftarrow +\frac{1}{m} \nabla_{\boldsymbol{\theta}} \sum_{i} L\left(f\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right), \boldsymbol{y}^{(i)}\right)$        
>
> 更新：$\theta \leftarrow \theta-\epsilon \hat{g}$        

#### 动量 随机梯度下降

动量法旨在加速学习，引入速度向量$\boldsymbol{v}$ ，代表参数在参数空间移动的方向和速率，定义为负梯度的指数衰减平均。“动量”一词来自物理，物理中负梯度是移动参数空间中粒子的力，动量是质量乘以速度，假设单位质量时，速度向量可以看做粒子的动量。

> 从训练集总采包含m个样本的小批量$\{x^{(1)},\cdots,x^{(m)}\}$        
> 以小批量上的梯度均值作为(无偏)梯度估计：$\boldsymbol{g} \leftarrow +\frac{1}{m} \nabla_{\boldsymbol{\theta}} \sum_{i} L\left(f\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right), \boldsymbol{y}^{(i)}\right)$         
>
> 计算速度更新：$\boldsymbol{v} \leftarrow \alpha \boldsymbol{v}-\epsilon \boldsymbol{g}$        
>
> 更新：$\theta \leftarrow \theta-\epsilon \hat{g}$       



## References

[1] Ian Goodfellow 花书 8.3节