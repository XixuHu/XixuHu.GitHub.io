---
title: 花书读书笔记
category: Deep Learning
tags:
  - Algorithm
---

$$
\begin{align*}
\newcommand{\Hilbert}[1]{\mathscr{#1}}
\newcommand{\dd}{\operatorname{d}}
\newcommand{\op}{\hat}
\newcommand{\id}{\mathbf{I}}
\newcommand{\Tr}[1]{\operatorname{Tr}\left\lbrace#1\right\rbrace}
\newcommand{\realset}{\mathbb{R}}
\newcommand{\intset}{\mathbb Z }
\newcommand{\comset }{\mathbb C }
\newcommand{\innerproduct}[1]{\left\langle #1 \right\rangle}
\renewcommand{\vec}{\mathbf}
\newcommand{\spl}[1]{\langle{#1}\rangle}
\newcommand{\inner}[2]{\left\langle{#1,#2}\right\rangle}
\newcommand{\form}{\tilde}
\newcommand{\abs}[1]{\left\vert{#1}\right\vert}
\newcommand{\bra}[1]{\left\langle{#1}\right\vert }
\newcommand{\ket}[1]{\left| {#1}\right\rangle}
\newcommand{\braket}[2]{\left\langle {#1} \; \middle|\;{#2} \right\rangle }
\newcommand{\mani}{\mathcal}
\newcommand{\field}{\mathscr}
\newcommand{\Tspace}[1]{T\! {#1}}
\newcommand{\D}[2]{\frac{\d {#1}}{\d {#2} }}
\newcommand{\Partial}[2]{\frac{\partial {#1} }{\partial {#2} }}
\newcommand{\op}{\hat}
\newcommand{\uvec}{\hat}
\newcommand{\defas}{: =}
\newcommand{\isdefas}{= :}
\newcommand{\Eqn}[1]{\text{(Eqn. }\ref{#1}\text{)}}
\newcommand{\dual}{\tilde}
\newcommand{\vard}{\mathfrak{d}}
\newcommand{\vare}{\mathfrak{e}}
\newcommand{\e}{\mathrm{e}}
\newcommand{\ii}{\mathrm{i}}
\newcommand{\blue}{\color{blue}}
\newcommand{\red}{\color{red}}
\newcommand{\norm}[1]{\left\|{#1}\right\|}
\newcommand{\set}[1]{\left\lbrace{#1}\right\rbrace}
\newcommand{\sgn}{\operatorname{sgn}}
\newcommand\myeq{\stackrel{\mbox{adiabatic}}{=}}
\newcommand{\avg}[1]{\left\langle {#1} \right\rangle}
\end{align*}
$$

#### 随机梯度下降

初始参数$\theta$，学习率$\epsilon$

> 从训练集总采包含m个样本的小批量$\{x^{(1)},\cdots,x^{(m)}\}$        
> 以小批量上的梯度均值作为(无偏)梯度估计：$\boldsymbol{g} \leftarrow +\frac{1}{m} \nabla_{\boldsymbol{\theta}} \sum_{i} L\left(f\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right), \boldsymbol{y}^{(i)}\right)$        
>
> 更新：$\theta \leftarrow \theta-\epsilon \hat{g}$        

#### 动量 随机梯度下降

动量法旨在加速学习，引入速度向量$\boldsymbol{v}$ ，代表参数在参数空间移动的方向和速率，定义为负梯度的指数衰减平均。“动量”一词来自物理，物理中负梯度是移动参数空间中粒子的力，动量是质量乘以速度，假设单位质量时，速度向量可以看做粒子的动量。

> 从训练集总采包含m个样本的小批量$\{x^{(1)},\cdots,x^{(m)}\}$        
> 以小批量上的梯度均值作为(无偏)梯度估计：$\boldsymbol{g} \leftarrow +\frac{1}{m} \nabla_{\boldsymbol{\theta}} \sum_{i} L\left(f\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right), \boldsymbol{y}^{(i)}\right)$         
>
> 计算速度更新：$\boldsymbol{v} \leftarrow \alpha \boldsymbol{v}-\epsilon \boldsymbol{g}$        
>
> 更新：$\theta \leftarrow \theta-\epsilon \hat{g}$       



##### References

花书 8.3节

---

卷积神经网络的生物学启发：Gabor函数


$$
w\left(x, y ; \alpha, \beta_{x}, \beta_{y}, f, \phi, x_{0}, y_{0}, \tau\right)=\alpha \exp \left(-\beta_{x} x^{\prime 2}-\beta_{y} y^{\prime 2}\right) \cos \left(f x^{\prime}+\phi\right)
$$


高斯因子视为阈值项，控制细胞的感受域，$\alpha$控制响应的总的量级，$\beta_x,\beta_y$控制感受域消退的速度；

余弦因子控制细胞如何相应沿$x'$轴的亮度变化。合在一起的时候，细胞对特定位置、特定方向、特定频率的亮度进行相应。当光波相位与余弦因子的相位相同时，细胞最兴奋。当图像亮时，权重为正；当图像暗时，权重为负。

基于Gabor函数，视觉细胞对图像的响应为


$$
s(I)=\sum_{x \in \mathbb{X}} \sum_{y \in \mathbb{Y}} w(x, y) I(x, y)
$$


$I(x,y)$表示二维坐标。

##### Reference

花书P224-225